"""
FastAPI Server for Remote Ambulance Inventory Queries
å¯å¾é ç«¯ Windows 11 ç­†é›»é€£ç·šæŸ¥è©¢çš„ API æœå‹™å™¨

é‹è¡Œæ–¹å¼:
    uvicorn server.api_server:app --host 0.0.0.0 --port 8000

é ç«¯è¨ªå•:
    http://SPARK_IP:8000/docs
"""

from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, RedirectResponse
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
import sys
import os
from pathlib import Path

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from ambulance_inventory.config import DatabaseConfig, OllamaConfig
from ambulance_inventory.database import DatabaseClient
from ambulance_inventory.ollama_client import OllamaClient
from ambulance_inventory.query_engine import QueryEngine
from ambulance_inventory.utils.logger import get_logger

logger = get_logger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="Ambulance Inventory Query API",
    description="è‡ªç„¶èªè¨€æŸ¥è©¢æ•‘è­·è»Šè¨­å‚™åº«å­˜ç³»çµ± - é ç«¯ API ç‰ˆæœ¬",
    version="2.1.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS configuration for remote access from Windows 11
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # In production, specify your Windows 11 IP
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Static files for web UI
web_dir = Path(__file__).parent.parent / "web"
if web_dir.exists():
    app.mount("/static", StaticFiles(directory=str(web_dir)), name="static")

# Global clients (initialized on startup)
db_client: Optional[DatabaseClient] = None
ollama_client: Optional[OllamaClient] = None
query_engine: Optional[QueryEngine] = None


# Pydantic models
class QueryRequest(BaseModel):
    """æŸ¥è©¢è«‹æ±‚"""
    question: str = Field(..., description="è‡ªç„¶èªè¨€å•é¡Œ", min_length=1)
    model: Optional[str] = Field(None, description="ä½¿ç”¨çš„æ¨¡å‹ï¼ˆå¯é¸ï¼Œä¸æŒ‡å®šå‰‡ä½¿ç”¨ç•¶å‰æ¨¡å‹ï¼‰")

    class Config:
        json_schema_extra = {
            "example": {
                "question": "è«‹åˆ—å‡ºæ‰€æœ‰æœ‰åº«å­˜çš„AEDé™¤é¡«å™¨ï¼ŒåŒ…å«å“ç‰Œã€å‹è™Ÿå’Œåº«å­˜æ•¸é‡",
                "model": "llama3:70b"
            }
        }


class ModelsResponse(BaseModel):
    """æ¨¡å‹åˆ—è¡¨å›æ‡‰"""
    models: List[str] = Field(..., description="å¯ç”¨æ¨¡å‹åˆ—è¡¨")
    current: str = Field(..., description="ç•¶å‰ä½¿ç”¨çš„æ¨¡å‹")


class ModelSelectRequest(BaseModel):
    """æ¨¡å‹é¸æ“‡è«‹æ±‚"""
    model: str = Field(..., description="è¦ä½¿ç”¨çš„æ¨¡å‹åç¨±")


class QueryResponse(BaseModel):
    """æŸ¥è©¢å›æ‡‰"""
    question: str = Field(..., description="åŸå§‹å•é¡Œ")
    sql: str = Field(..., description="ç”Ÿæˆçš„ SQL æŸ¥è©¢")
    answer: str = Field(..., description="AI å›ç­”")
    success: bool = Field(..., description="æŸ¥è©¢æ˜¯å¦æˆåŠŸ")
    error: Optional[str] = Field(None, description="éŒ¯èª¤è¨Šæ¯ï¼ˆå¦‚æœæœ‰ï¼‰")


class HealthResponse(BaseModel):
    """å¥åº·æª¢æŸ¥å›æ‡‰"""
    status: str
    database: bool
    ollama: bool
    model: str
    version: str


class TableInfo(BaseModel):
    """è³‡æ–™è¡¨è³‡è¨Š"""
    table_name: str
    columns: List[Dict[str, str]]


@app.on_event("startup")
async def startup_event():
    """æœå‹™å™¨å•Ÿå‹•æ™‚åˆå§‹åŒ–"""
    global db_client, ollama_client, query_engine

    try:
        logger.info("ğŸš€ Initializing API server...")

        # Initialize database client
        db_config = DatabaseConfig.from_env()
        db_client = DatabaseClient(db_config)
        logger.info("âœ… Database client initialized")

        # Initialize Ollama client
        ollama_config = OllamaConfig.from_env()
        ollama_client = OllamaClient(ollama_config)
        logger.info(f"âœ… Ollama client initialized (model: {ollama_config.model})")

        # Initialize query engine
        query_engine = QueryEngine(db_client, ollama_client)
        logger.info("âœ… Query engine initialized")

        logger.info("ğŸ‰ API server ready for remote connections!")

    except Exception as e:
        logger.error(f"âŒ Failed to initialize server: {e}")
        raise


@app.on_event("shutdown")
async def shutdown_event():
    """æœå‹™å™¨é—œé–‰æ™‚æ¸…ç†"""
    global db_client

    if db_client:
        db_client.close()
        logger.info("Database connection closed")


@app.get("/", tags=["General"])
async def root():
    """æ ¹ç«¯é» - é‡å®šå‘åˆ° Web UI"""
    return RedirectResponse(url="/web")


@app.get("/web", tags=["General"])
async def web_ui():
    """Web UI ä»‹é¢"""
    web_file = Path(__file__).parent.parent / "web" / "index.html"
    if web_file.exists():
        return FileResponse(str(web_file), media_type="text/html")
    return {"error": "Web UI not found", "path": str(web_file)}


@app.get("/api", tags=["General"])
async def api_info():
    """API è³‡è¨Š"""
    model_name = ollama_client.config.model if ollama_client else "unknown"
    return {
        "message": "Ambulance Inventory Query API",
        "version": "2.1.0",
        "model": model_name,
        "docs": "/docs",
        "health": "/health",
        "web_ui": "/web"
    }


@app.get("/health", response_model=HealthResponse, tags=["General"])
async def health_check():
    """
    å¥åº·æª¢æŸ¥ç«¯é»

    æª¢æŸ¥è³‡æ–™åº«å’Œ Ollama é€£æ¥ç‹€æ…‹
    """
    try:
        # Check database
        db_ok = db_client.test_connection() if db_client else False

        # Check Ollama
        ollama_ok = ollama_client.test_connection() if ollama_client else False

        model_name = ollama_client.config.model if ollama_client else "unknown"

        status = "healthy" if (db_ok and ollama_ok) else "unhealthy"

        return HealthResponse(
            status=status,
            database=db_ok,
            ollama=ollama_ok,
            model=model_name,
            version="2.1.0"
        )
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        raise HTTPException(status_code=503, detail=f"Service unavailable: {str(e)}")


@app.post("/query", response_model=QueryResponse, tags=["Query"])
async def query(request: QueryRequest):
    """
    åŸ·è¡Œè‡ªç„¶èªè¨€æŸ¥è©¢

    æ¥æ”¶è‡ªç„¶èªè¨€å•é¡Œï¼Œç”Ÿæˆ SQLï¼ŒåŸ·è¡ŒæŸ¥è©¢ï¼Œè¿”å›å›ç­”

    Args:
        request: åŒ…å«å•é¡Œçš„æŸ¥è©¢è«‹æ±‚ï¼Œå¯é¸æŒ‡å®šæ¨¡å‹

    Returns:
        QueryResponse: åŒ…å« SQLã€ç­”æ¡ˆç­‰è³‡è¨Š
    """
    if not query_engine:
        raise HTTPException(status_code=503, detail="Query engine not initialized")

    # Check Ollama connection first
    if ollama_client and not ollama_client.test_connection():
        return QueryResponse(
            question=request.question,
            sql="",
            answer="",
            success=False,
            error="Ollama service is not available. Please ensure Ollama is running on the server."
        )

    try:
        # Temporarily switch model if specified
        original_model = None
        if request.model and ollama_client:
            available_models = ollama_client.get_available_models()
            if request.model in available_models:
                original_model = ollama_client.config.model
                ollama_client.config.model = request.model
                logger.info(f"ğŸ“ Using model: {request.model}")

        logger.info(f"ğŸ“ Received query: {request.question}")

        # Execute query
        sql, answer = query_engine.query(request.question)

        # Restore original model if it was changed
        if original_model:
            ollama_client.config.model = original_model

        # Handle None values (Ollama might have failed silently)
        if sql is None or answer is None:
            return QueryResponse(
                question=request.question,
                sql=sql or "",
                answer=answer or "",
                success=False,
                error="Query failed - Ollama may not be responding. Check if Ollama service is running."
            )

        logger.info(f"âœ… Query successful")

        return QueryResponse(
            question=request.question,
            sql=sql,
            answer=answer,
            success=True,
            error=None
        )

    except Exception as e:
        # Restore original model on error
        if original_model and ollama_client:
            ollama_client.config.model = original_model
        logger.error(f"âŒ Query failed: {e}")
        return QueryResponse(
            question=request.question,
            sql="",
            answer="",
            success=False,
            error=str(e)
        )


@app.get("/tables", response_model=List[TableInfo], tags=["Database"])
async def get_tables():
    """
    å–å¾—è³‡æ–™è¡¨çµæ§‹è³‡è¨Š

    Returns:
        List[TableInfo]: æ‰€æœ‰è³‡æ–™è¡¨åŠå…¶æ¬„ä½è³‡è¨Š
    """
    if not db_client:
        raise HTTPException(status_code=503, detail="Database client not initialized")

    try:
        tables_info = []

        # Get table schema
        schema_query = """
        SELECT
            table_name,
            column_name,
            data_type,
            is_nullable
        FROM information_schema.columns
        WHERE table_schema = 'public'
        ORDER BY table_name, ordinal_position;
        """

        rows = db_client.execute_query(schema_query)

        # Group by table
        from collections import defaultdict
        tables_dict = defaultdict(list)

        for row in rows:
            tables_dict[row[0]].append({
                "column_name": row[1],
                "data_type": row[2],
                "nullable": row[3]
            })

        # Convert to TableInfo list
        for table_name, columns in tables_dict.items():
            tables_info.append(TableInfo(
                table_name=table_name,
                columns=columns
            ))

        return tables_info

    except Exception as e:
        logger.error(f"Failed to get tables: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get tables: {str(e)}")


@app.get("/demo-queries", tags=["Query"])
async def get_demo_queries():
    """
    å–å¾— Demo æŸ¥è©¢ç¯„ä¾‹

    Returns:
        List[str]: Demo æŸ¥è©¢åˆ—è¡¨
    """
    demo_queries = [
        "è«‹åˆ—å‡ºæ‰€æœ‰æœ‰åº«å­˜çš„AEDé™¤é¡«å™¨ï¼ŒåŒ…å«å“ç‰Œã€å‹è™Ÿå’Œåº«å­˜æ•¸é‡",
        "è«‹åˆ—å‡ºæ‰€æœ‰æ“”æ¶è¨­å‚™çš„å“ç‰Œã€å‹è™Ÿå’Œåº«å­˜æ•¸é‡",
        "è«‹åˆ—å‡ºå–®åƒ¹ä½æ–¼50000å…ƒçš„ç›£è¦–å™¨ï¼ŒåŒ…å«å“ç‰Œã€å‹è™Ÿå’Œåƒ¹æ ¼",
        "è«‹åˆ—å‡ºåº«å­˜æ•¸é‡ä½æ–¼10ä»¶çš„å•†å“ï¼ŒåŒ…å«ç”¢å“åç¨±ã€åˆ†é¡å’Œåº«å­˜æ•¸é‡",
        "è«‹åˆ—å‡ºæ‰€æœ‰Philipså“ç‰Œçš„ç”¢å“ï¼ŒåŒ…å«åç¨±ã€å‹è™Ÿå’Œå–®åƒ¹",
    ]

    return {
        "demo_queries": demo_queries,
        "usage": "ä½¿ç”¨ POST /query ç«¯é»åŸ·è¡Œé€™äº›æŸ¥è©¢"
    }


@app.get("/api/models", response_model=ModelsResponse, tags=["Models"])
async def get_available_models():
    """
    å–å¾—å¯ç”¨çš„ Ollama æ¨¡å‹åˆ—è¡¨

    Returns:
        ModelsResponse: å¯ç”¨æ¨¡å‹åˆ—è¡¨å’Œç•¶å‰ä½¿ç”¨çš„æ¨¡å‹
    """
    if not ollama_client:
        raise HTTPException(status_code=503, detail="Ollama client not initialized")

    try:
        models = ollama_client.get_available_models()
        current = ollama_client.config.model

        return ModelsResponse(
            models=models,
            current=current
        )
    except Exception as e:
        logger.error(f"Failed to get models: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get models: {str(e)}")


@app.post("/api/models/select", tags=["Models"])
async def select_model(request: ModelSelectRequest):
    """
    åˆ‡æ›ä½¿ç”¨çš„ Ollama æ¨¡å‹

    Args:
        request: åŒ…å«æ¨¡å‹åç¨±çš„è«‹æ±‚

    Returns:
        åˆ‡æ›çµæœ
    """
    global ollama_client, query_engine

    if not ollama_client:
        raise HTTPException(status_code=503, detail="Ollama client not initialized")

    try:
        # Check if model is available
        available_models = ollama_client.get_available_models()

        if request.model not in available_models:
            raise HTTPException(
                status_code=400,
                detail=f"Model '{request.model}' not found. Available: {available_models}"
            )

        # Update model in config
        old_model = ollama_client.config.model
        ollama_client.config.model = request.model

        # Recreate query engine with new model
        query_engine = QueryEngine(db_client, ollama_client)

        logger.info(f"ğŸ”„ Model switched from {old_model} to {request.model}")

        return {
            "success": True,
            "message": f"Model switched to {request.model}",
            "previous": old_model,
            "current": request.model
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to switch model: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to switch model: {str(e)}")


if __name__ == "__main__":
    import uvicorn

    print("ğŸš€ Starting API Server...")
    print("ğŸ“– API Documentation: http://localhost:8000/docs")
    print("ğŸ” Health Check: http://localhost:8000/health")

    uvicorn.run(
        app,
        host="0.0.0.0",  # Listen on all interfaces for remote access
        port=8000,
        log_level="info"
    )
