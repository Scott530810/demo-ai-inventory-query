# Windows 11 æœ¬åœ°éƒ¨ç½²æŒ‡å—

ä½¿ç”¨ Ollama åœ¨æœ¬åœ°é‹è¡Œ AI åº«å­˜æŸ¥è©¢ç³»çµ±

## ç³»çµ±éœ€æ±‚

- **ä½œæ¥­ç³»çµ±**: Windows 11
- **GPU**: NVIDIA RTX ç³»åˆ— (å»ºè­° 8GB+ VRAM)
- **è»Ÿé«”**: Docker Desktop, Ollama

## å¿«é€Ÿé–‹å§‹ (5 åˆ†é˜)

### æ­¥é©Ÿ 1: å®‰è£ Ollama

1. ä¸‹è¼‰å®‰è£: https://ollama.com/download
2. ä¸‹è¼‰æ¨¡å‹:
```powershell
ollama pull llama3:70b
```

### æ­¥é©Ÿ 2: è¨­å®š Ollama å…è¨±å¤–éƒ¨è¨ªå•

```powershell
# PowerShell (ç®¡ç†å“¡æ¨¡å¼)
[Environment]::SetEnvironmentVariable("OLLAMA_HOST", "0.0.0.0", "User")
```

é‡å•Ÿ Ollama (ç³»çµ±æ‰˜ç›¤å³éµ â†’ Quit â†’ é‡æ–°é–‹å•Ÿ)

### æ­¥é©Ÿ 3: å•Ÿå‹•ç³»çµ±

```powershell
cd C:\path\to\demo-ai-inventory-query
.\run-ollama.ps1

# é¸æ“‡:
# 1 â†’ å•Ÿå‹•ç³»çµ±
# 2 â†’ ç³»çµ±æª¢æŸ¥
# 3 â†’ åŸ·è¡Œ Demo
# 4 â†’ äº’å‹•æ¨¡å¼
```

---

## Docker ä½¿ç”¨æ–¹å¼

### æ‰‹å‹•å•Ÿå‹•

```bash
# æ§‹å»ºä¸¦å•Ÿå‹•
docker compose -f docker-compose.ollama.yml up -d --build

# é€²å…¥äº’å‹•æ¨¡å¼
docker exec -it ambulance-query-ollama python run_refactored.py --interactive

# åŸ·è¡Œ Demo
docker exec -it ambulance-query-ollama python run_refactored.py --demo

# ç³»çµ±æª¢æŸ¥
docker exec -it ambulance-query-ollama python run_refactored.py --check
```

### å®¹å™¨ç®¡ç†

```bash
# æŸ¥çœ‹ç‹€æ…‹
docker compose -f docker-compose.ollama.yml ps

# æŸ¥çœ‹æ—¥èªŒ
docker compose -f docker-compose.ollama.yml logs -f query-app-ollama

# åœæ­¢æœå‹™
docker compose -f docker-compose.ollama.yml down

# å®Œå…¨æ¸…ç† (å«è³‡æ–™)
docker compose -f docker-compose.ollama.yml down -v
```

---

## é…ç½®èªªæ˜

### ç’°å¢ƒè®Šæ•¸

åœ¨ `docker-compose.ollama.yml` ä¸­è¨­å®š:

| è®Šæ•¸ | èªªæ˜ | é è¨­å€¼ |
|------|------|--------|
| `OLLAMA_HOST` | Ollama æœå‹™ä½å€ | `http://host.docker.internal:11434` |
| `OLLAMA_MODEL` | ä½¿ç”¨çš„æ¨¡å‹ | `llama3:70b` |
| `OLLAMA_TIMEOUT` | è«‹æ±‚è¶…æ™‚ç§’æ•¸ | `120` |
| `DB_HOST` | è³‡æ–™åº«ä¸»æ©Ÿ | `postgres` |
| `DB_NAME` | è³‡æ–™åº«åç¨± | `ambulance_inventory` |

### æ›´æ›æ¨¡å‹

ç·¨è¼¯ `docker-compose.ollama.yml`:

```yaml
environment:
  OLLAMA_MODEL: llama3:8b  # æ›´å¿«ä½†è¼ƒä¸æº–ç¢º
```

æˆ–åœ¨äº’å‹•æ¨¡å¼ä¸­é¸æ“‡ã€Œåˆ‡æ›æ¨¡å‹ã€ã€‚

---

## ä½¿ç”¨ç¯„ä¾‹

### ç°¡å–®æŸ¥è©¢

```
ğŸ’­ è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ: è«‹å• AED é™¤é¡«å™¨é‚„æœ‰å“ªå¹¾æ¬¾æœ‰åº«å­˜ï¼Ÿ

ğŸ¤– AI å›æ‡‰:
ç›®å‰æœ‰åº«å­˜çš„ AED é™¤é¡«å™¨å…± 4 æ¬¾ï¼š
1. Philips HeartStart FRx - åº«å­˜ 15 å°
2. Mindray BeneHeart D1 - åº«å­˜ 12 å°
...
```

### è¤‡é›œæŸ¥è©¢

```
ğŸ’­ è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ: æˆ‘éœ€è¦é…å‚™ä¸€å°æ–°æ•‘è­·è»Šï¼Œé ç®— 15 è¬ï¼Œè«‹æ¨è–¦è¨­å‚™æ¸…å–®

ğŸ¤– AI å›æ‡‰:
æ ¹æ“šæ‚¨ 15 è¬çš„é ç®—ï¼Œæ¨è–¦ä»¥ä¸‹é…ç½®ï¼š
1. AED é™¤é¡«å™¨ - Mindray BeneHeart D1 (68,000 å…ƒ)
2. æ°§æ°£è¨­å‚™ - æ”œå¸¶å¼æ°§æ°£ç“¶ x3 (25,500 å…ƒ)
...
ç¸½è¨ˆ: 143,500 å…ƒ
```

---

## æ•ˆèƒ½åƒè€ƒ

| GPU | æ¨¡å‹ | VRAM | SQL ç”Ÿæˆ | å›æ‡‰ç”Ÿæˆ |
|-----|------|------|----------|----------|
| RTX 4070 | llama3:8b | ~5GB | 2-4 ç§’ | 3-5 ç§’ |
| RTX 4070 | llama3:70b | ~40GB | 4-8 ç§’ | 5-10 ç§’ |
| RTX 5070 | llama3:70b | ~40GB | 3-6 ç§’ | 4-8 ç§’ |

---

## æ•…éšœæ’é™¤

### ç„¡æ³•é€£æ¥åˆ° Ollama

```powershell
# æª¢æŸ¥ Ollama æ˜¯å¦é‹è¡Œ
curl http://localhost:11434/api/tags

# ç¢ºèªç’°å¢ƒè®Šæ•¸
echo $env:OLLAMA_HOST

# é‡å•Ÿ Ollama
```

### å®¹å™¨ç„¡æ³•è¨ªå• host.docker.internal

```powershell
# Docker Desktop è¨­å®š
# Settings â†’ Resources â†’ Network
# ç¢ºèª "Use the host network" å·²å•Ÿç”¨
```

### VRAM ä¸è¶³

```powershell
# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
ollama pull llama3:8b

# ä¿®æ”¹ docker-compose.ollama.yml
# OLLAMA_MODEL: llama3:8b
```

### è³‡æ–™åº«é€£æ¥å¤±æ•—

```bash
# æª¢æŸ¥è³‡æ–™åº«æœå‹™
docker compose -f docker-compose.ollama.yml ps postgres

# æª¢æŸ¥å¥åº·ç‹€æ…‹
docker inspect ambulance-db-ollama | grep -A 10 Health
```

---

## æª”æ¡ˆçµæ§‹

```
demo-ai-inventory-query/
â”œâ”€â”€ docker-compose.ollama.yml    # Docker é…ç½®
â”œâ”€â”€ Dockerfile.ollama            # Docker æ˜ åƒ
â”œâ”€â”€ run-ollama.ps1               # PowerShell å•Ÿå‹•è…³æœ¬
â”œâ”€â”€ run-ollama.sh                # Bash å•Ÿå‹•è…³æœ¬ (WSL)
â”œâ”€â”€ run_refactored.py            # Python å…¥å£
â””â”€â”€ ambulance_inventory/         # æ ¸å¿ƒæ¨¡çµ„
```

---

**ç‰ˆæœ¬**: 2.1.0
**æ›´æ–°æ—¥æœŸ**: 2026-01-18
